{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证PIL,opecv,tensor之间的相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/lyma/FocusOnDepth/datasets/inria/images/0.jpg\"\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL 相关属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_Image__transformer', '__array_interface__', '__class__', '__copy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_close_exclusive_fp_after_loading', '_copy', '_crop', '_dump', '_ensure_mutable', '_exclusive_fp', '_exif', '_expand', '_get_safe_box', '_getexif', '_getmp', '_min_frame', '_new', '_open', '_repr_png_', '_seek_check', '_size', 'alpha_composite', 'app', 'applist', 'bits', 'category', 'close', 'convert', 'copy', 'crop', 'custom_mimetype', 'decoderconfig', 'decodermaxblock', 'draft', 'effect_spread', 'entropy', 'filename', 'filter', 'format', 'format_description', 'fp', 'frombytes', 'fromstring', 'get_format_mimetype', 'getbands', 'getbbox', 'getchannel', 'getcolors', 'getdata', 'getexif', 'getextrema', 'getim', 'getpalette', 'getpixel', 'getprojection', 'height', 'histogram', 'huffman_ac', 'huffman_dc', 'icclist', 'im', 'info', 'layer', 'layers', 'load', 'load_djpeg', 'load_end', 'load_prepare', 'load_read', 'mode', 'offset', 'palette', 'paste', 'point', 'putalpha', 'putdata', 'putpalette', 'putpixel', 'pyaccess', 'quantization', 'quantize', 'readonly', 'reduce', 'remap_palette', 'resize', 'rotate', 'save', 'seek', 'show', 'size', 'split', 'tell', 'thumbnail', 'tile', 'tobitmap', 'tobytes', 'toqimage', 'toqpixmap', 'tostring', 'transform', 'transpose', 'verify', 'width']\n",
      "image mode: RGB\n",
      "image size: (960, 540) width: 960 height: 540\n",
      "R:1, G:1, B:0 in 1,1\n"
     ]
    }
   ],
   "source": [
    "pil_img = Image.open(img_path)\n",
    "print(dir(pil_img))\n",
    "print(\"image mode:\", pil_img.mode)\n",
    "print(\"image size:\", pil_img.size, \"width:\", pil_img.width, \"height:\", pil_img.height)\n",
    "r, g, b = pil_img.getpixel((1, 1))\n",
    "print(\"R:{}, G:{}, B:{} in 1,1\".format(r,g,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opencv 相关属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_function__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n",
      "HWC(row, col, channel): (540, 960, 3) 1555200\n",
      "R:1, G:1, B:0 in 1,1\n"
     ]
    }
   ],
   "source": [
    "cv_img = cv2.imread(img_path)\n",
    "print(dir(cv_img))\n",
    "print(\"HWC(row, col, channel):\", cv_img.shape, cv_img.size)\n",
    "b,g,r = cv_img[1,1]\n",
    "print(\"R:{}, G:{}, B:{} in 1,1\".format(r,g,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用torch读、转换PIL,opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHW: torch.Size([3, 540, 960]) tensor(0.) tensor(1.)\n",
      "CHW: torch.Size([3, 540, 960]) tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "transform_totensor = transforms.Compose([\n",
    "    transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "    ])\n",
    "pil_tensor = transform_totensor(pil_img)\n",
    "print(\"CHW:\", pil_tensor.shape, pil_tensor.min(), pil_tensor.max())\n",
    "cv_tensor = transform_totensor(cv_img)\n",
    "print(\"CHW:\", cv_tensor.shape, cv_tensor.min(), cv_tensor.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL-->Tensor直接用ToPILImage()实现\n",
    ".convert('RGB')不是必要的！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img_transformed = transforms.ToPILImage()(pil_tensor)#.convert('RGB')\n",
    "pil_img_transformed.save(\"pil_img_transformed.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opencv-->Tensor\n",
    "np.transpose是必要的！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_img_transformed = cv_tensor.numpy()*255\n",
    "cv_img_transformed = cv_img_transformed.astype('uint8')\n",
    "cv_img_transformed = np.transpose(cv_img_transformed, (1,2,0))\n",
    "cv2.imwrite(\"cv_img_transformed.jpg\",cv_img_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL-->opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:0, G:1, B:1 in 1,1\n"
     ]
    }
   ],
   "source": [
    "pil_to_cv_img = cv2.cvtColor(np.asarray(cv_img),cv2.COLOR_RGB2BGR)  \n",
    "b,g,r = pil_to_cv_img[1,1]\n",
    "print(\"R:{}, G:{}, B:{} in 1,1\".format(r,g,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opencv-->PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:0, G:1, B:1 in 1,1\n"
     ]
    }
   ],
   "source": [
    "cv_to_pil_img = Image.fromarray(cv_img)\n",
    "r, g, b = cv_to_pil_img.getpixel((1, 1))\n",
    "print(\"R:{}, G:{}, B:{} in 1,1\".format(r,g,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03ac31138da60eb9474b5fec0077037ceffae68c9c3533ed2b1b84a7093662f8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
